-----------------------------------------------------------------
      name:  <unnamed>
       log:  /Users/Sun/Desktop/Econometrics/stata/intro.log
  log type:  text
 opened on:   1 Apr 2017, 08:31:59

. set more off

. 
. /*
> Ordinarily, the next step would be to read in a dataset, but se
> eing as your 
> homework calls for simulating data, we'll simulate a dataset he
> re too. 
> Let's make a dataset that follows some workers over time and re
> cords their
> wage each year. To keep things managable, let's say we observe 
> 10 workers from
> ages 31 to 35. 
> */
. 
. /*
> Start by using set obs to make one observation per worker. 
> */
. 
. set obs 10
number of observations (_N) was 0, now 10

. 
. /*
> Now our dataset has 10 observations, but there's no data in any
>  of them. We can 
> see this using 'd', which is short for 'describe'.
> */
. d

Contains data
  obs:            10                          
 vars:             0                          
 size:             0                          
Sorted by: 
     Note: Dataset has changed since last saved.

. 
. /*
> Let's give each observation a worker ID. We're going to refer t
> o Stata's
> internal index using '_n'. The observation that has _n==1 is th
> e first
> observation in the dataset. If you were to look at the data, it
>  would appear at
> the top. The observation with _n==_N would instead appear at th
> e bottom. We'll
> use this to (gen)erate a variable that has the same value as St
> ata's internal 
> index.
> */
. 
. gen id = _n

. 
. /*
> Now list the data to see that each worker has a unique ID.
> */
. 
. list

     +----+
     | id |
     |----|
  1. |  1 |
  2. |  2 |
  3. |  3 |
  4. |  4 |
  5. |  5 |
     |----|
  6. |  6 |
  7. |  7 |
  8. |  8 |
  9. |  9 |
 10. | 10 |
     +----+

. 
. /*
> Now let's add a time dimension. We'll use the the 'expand' comm
> and, which
> takes each observation in the dataset and copies it the number 
> of times you tell
> it to.
> */
. expand 5
(40 observations created)

. 
. /*
> We can see that we now have 5 observations for each ID using th
> e (tab)ulate
> command.
> */
. tab id

         id |      Freq.     Percent        Cum.
------------+-----------------------------------
          1 |          5       10.00       10.00
          2 |          5       10.00       20.00
          3 |          5       10.00       30.00
          4 |          5       10.00       40.00
          5 |          5       10.00       50.00
          6 |          5       10.00       60.00
          7 |          5       10.00       70.00
          8 |          5       10.00       80.00
          9 |          5       10.00       90.00
         10 |          5       10.00      100.00
------------+-----------------------------------
      Total |         50      100.00

. 
. /*
> Now we need to assign ages to the observation. It's going to ta
> ke a little more
> tech than before. First we will 'sort' the data by id. This wil
> l put the
> observation with the lowest value of id at the top, and with th
> e highest value
> at the bottom. Then we will perform a command 'by' id. This is 
> a very neat
> tool that essentially tells Stata to consider the observations 
> associated with
> each value of id as a different dataset, and perform the comman
> d in each one
> individually. This extends to Stata's internal index, so we can
>  use the same
> trick as before to give each observation an age. 
> */
. sort id

. by id: gen age = _n

. 
. /*
> Let's look at the data to make sure it worked.
> */
. list

     +----------+
     | id   age |
     |----------|
  1. |  1     1 |
  2. |  1     2 |
  3. |  1     3 |
  4. |  1     4 |
  5. |  1     5 |
     |----------|
  6. |  2     1 |
  7. |  2     2 |
  8. |  2     3 |
  9. |  2     4 |
 10. |  2     5 |
     |----------|
 11. |  3     1 |
 12. |  3     2 |
 13. |  3     3 |
 14. |  3     4 |
 15. |  3     5 |
     |----------|
 16. |  4     1 |
 17. |  4     2 |
 18. |  4     3 |
 19. |  4     4 |
 20. |  4     5 |
     |----------|
 21. |  5     1 |
 22. |  5     2 |
 23. |  5     3 |
 24. |  5     4 |
 25. |  5     5 |
     |----------|
 26. |  6     1 |
 27. |  6     2 |
 28. |  6     3 |
 29. |  6     4 |
 30. |  6     5 |
     |----------|
 31. |  7     1 |
 32. |  7     2 |
 33. |  7     3 |
 34. |  7     4 |
 35. |  7     5 |
     |----------|
 36. |  8     1 |
 37. |  8     2 |
 38. |  8     3 |
 39. |  8     4 |
 40. |  8     5 |
     |----------|
 41. |  9     1 |
 42. |  9     2 |
 43. |  9     3 |
 44. |  9     4 |
 45. |  9     5 |
     |----------|
 46. | 10     1 |
 47. | 10     2 |
 48. | 10     3 |
 49. | 10     4 |
 50. | 10     5 |
     +----------+

. 
. /*
> It only kinda worked. 1-5 are not realistic ages for people in 
> the labor market.
> Let's fix that by replacing the value in the age variable.
> */
. replace age = age + 30
(50 real changes made)

. 
. /*
> Let's (sum)mmarize the age variable to check that the ages in o
> ur dataset line 
> up with our expectations.
> */
. sum age

    Variable |        Obs        Mean    Std. Dev.       Min     
>    Max
-------------+---------------------------------------------------
> ------
         age |         50          33    1.428571         31     
>     35

.         
. /*
> OK, so now we have the skeleton of our dataset, but we still ne
> ed wages!
> Collecting that would be hard, so let's just use a random numbe
> r generator. The
> function rnormal() will draw from the standard normal distribut
> ion (mean 0,
> standard deviation 1). Before we do anything random though, let
> 's set the seed
> of the random number generator so every time we run this progra
> m, we get
> the same random draws.
> */
. set seed 5142017

. gen wage = rnormal()    

. 
. /*
> Now that looks like a proper dataset. (Well, except for all the
>  negative wages,
> but just go with it).
> */
. list

     +----------------------+
     | id   age        wage |
     |----------------------|
  1. |  1    31    1.211904 |
  2. |  1    32   -.3612679 |
  3. |  1    33    1.126974 |
  4. |  1    34    .8667185 |
  5. |  1    35   -.2732491 |
     |----------------------|
  6. |  2    31    .2470128 |
  7. |  2    32   -1.068483 |
  8. |  2    33   -.1085389 |
  9. |  2    34    1.652032 |
 10. |  2    35   -.9383892 |
     |----------------------|
 11. |  3    31   -1.607959 |
 12. |  3    32    .1928903 |
 13. |  3    33    .6054147 |
 14. |  3    34   -.3051899 |
 15. |  3    35    1.114255 |
     |----------------------|
 16. |  4    31   -.0898557 |
 17. |  4    32    .6663027 |
 18. |  4    33   -.3823017 |
 19. |  4    34    .4554643 |
 20. |  4    35   -.6439326 |
     |----------------------|
 21. |  5    31    .2606112 |
 22. |  5    32   -1.452613 |
 23. |  5    33   -.7583048 |
 24. |  5    34    1.970305 |
 25. |  5    35   -.3061868 |
     |----------------------|
 26. |  6    31    .1273191 |
 27. |  6    32    .1132783 |
 28. |  6    33   -1.265171 |
 29. |  6    34   -.3444634 |
 30. |  6    35    .9897245 |
     |----------------------|
 31. |  7    31    1.365968 |
 32. |  7    32    .4271485 |
 33. |  7    33   -.3066736 |
 34. |  7    34    .7777075 |
 35. |  7    35   -1.389155 |
     |----------------------|
 36. |  8    31   -.2772346 |
 37. |  8    32   -.1689324 |
 38. |  8    33    .1919505 |
 39. |  8    34   -.1805429 |
 40. |  8    35    .0898568 |
     |----------------------|
 41. |  9    31    .1654728 |
 42. |  9    32    .6335773 |
 43. |  9    33   -.2884277 |
 44. |  9    34    1.663885 |
 45. |  9    35    1.390535 |
     |----------------------|
 46. | 10    31   -1.845122 |
 47. | 10    32   -.5377126 |
 48. | 10    33    2.255249 |
 49. | 10    34    .6103685 |
 50. | 10    35   -1.433175 |
     +----------------------+

. 
. /*
> Next, let's analyze our data. Maybe we want to know how far eac
> h wage observation
> is from the average wage in the dataset. For that, we'll use 'e
> gen', which is a
> very powerful command that lets you calculate simple things lik
> e averages, 
> standard deviations, maxima, minima, etc. and store them as new
>  variables in our
> dataset. 
> */
. egen average_wage = mean(wage)

. gen wage_deviation = wage - average_wage

. list

     +---------------------------------------------+
     | id   age        wage   averag~e   wage_de~n |
     |---------------------------------------------|
  1. |  1    31    1.211904   .0967809    1.115123 |
  2. |  1    32   -.3612679   .0967809   -.4580488 |
  3. |  1    33    1.126974   .0967809    1.030193 |
  4. |  1    34    .8667185   .0967809    .7699376 |
  5. |  1    35   -.2732491   .0967809     -.37003 |
     |---------------------------------------------|
  6. |  2    31    .2470128   .0967809     .150232 |
  7. |  2    32   -1.068483   .0967809   -1.165264 |
  8. |  2    33   -.1085389   .0967809   -.2053198 |
  9. |  2    34    1.652032   .0967809    1.555251 |
 10. |  2    35   -.9383892   .0967809    -1.03517 |
     |---------------------------------------------|
 11. |  3    31   -1.607959   .0967809    -1.70474 |
 12. |  3    32    .1928903   .0967809    .0961095 |
 13. |  3    33    .6054147   .0967809    .5086338 |
 14. |  3    34   -.3051899   .0967809   -.4019708 |
 15. |  3    35    1.114255   .0967809    1.017474 |
     |---------------------------------------------|
 16. |  4    31   -.0898557   .0967809   -.1866366 |
 17. |  4    32    .6663027   .0967809    .5695218 |
 18. |  4    33   -.3823017   .0967809   -.4790825 |
 19. |  4    34    .4554643   .0967809    .3586835 |
 20. |  4    35   -.6439326   .0967809   -.7407135 |
     |---------------------------------------------|
 21. |  5    31    .2606112   .0967809    .1638304 |
 22. |  5    32   -1.452613   .0967809   -1.549394 |
 23. |  5    33   -.7583048   .0967809   -.8550857 |
 24. |  5    34    1.970305   .0967809    1.873524 |
 25. |  5    35   -.3061868   .0967809   -.4029677 |
     |---------------------------------------------|
 26. |  6    31    .1273191   .0967809    .0305382 |
 27. |  6    32    .1132783   .0967809    .0164974 |
 28. |  6    33   -1.265171   .0967809   -1.361951 |
 29. |  6    34   -.3444634   .0967809   -.4412443 |
 30. |  6    35    .9897245   .0967809    .8929436 |
     |---------------------------------------------|
 31. |  7    31    1.365968   .0967809    1.269187 |
 32. |  7    32    .4271485   .0967809    .3303676 |
 33. |  7    33   -.3066736   .0967809   -.4034544 |
 34. |  7    34    .7777075   .0967809    .6809266 |
 35. |  7    35   -1.389155   .0967809   -1.485936 |
     |---------------------------------------------|
 36. |  8    31   -.2772346   .0967809   -.3740155 |
 37. |  8    32   -.1689324   .0967809   -.2657133 |
 38. |  8    33    .1919505   .0967809    .0951696 |
 39. |  8    34   -.1805429   .0967809   -.2773237 |
 40. |  8    35    .0898568   .0967809   -.0069241 |
     |---------------------------------------------|
 41. |  9    31    .1654728   .0967809    .0686919 |
 42. |  9    32    .6335773   .0967809    .5367965 |
 43. |  9    33   -.2884277   .0967809   -.3852086 |
 44. |  9    34    1.663885   .0967809    1.567104 |
 45. |  9    35    1.390535   .0967809    1.293754 |
     |---------------------------------------------|
 46. | 10    31   -1.845122   .0967809   -1.941903 |
 47. | 10    32   -.5377126   .0967809   -.6344935 |
 48. | 10    33    2.255249   .0967809    2.158468 |
 49. | 10    34    .6103685   .0967809    .5135877 |
 50. | 10    35   -1.433175   .0967809   -1.529956 |
     +---------------------------------------------+

. 
. /*
> Maybe we're more interested in how far each wage observation is
>  from the average
> for that worker. The good news is that 'egen' plays nicely with
>  'by'. 
> */
. by id: egen worker_average_wage = mean(wage)

. gen worker_wage_deviation = wage - worker_average_wage

. 
. /*
> Let's list the data, but  now just look at the variables that a
> re relevant to 
> this question.
> */
. list id age wage worker_*

     +----------------------------------------------+
     | id   age        wage   worker_~e   worker_~n |
     |----------------------------------------------|
  1. |  1    31    1.211904    .5142158    .6976883 |
  2. |  1    32   -.3612679    .5142158   -.8754837 |
  3. |  1    33    1.126974    .5142158    .6127577 |
  4. |  1    34    .8667185    .5142158    .3525027 |
  5. |  1    35   -.2732491    .5142158    -.787465 |
     |----------------------------------------------|
  6. |  2    31    .2470128   -.0432732     .290286 |
  7. |  2    32   -1.068483   -.0432732   -1.025209 |
  8. |  2    33   -.1085389   -.0432732   -.0652657 |
  9. |  2    34    1.652032   -.0432732    1.695305 |
 10. |  2    35   -.9383892   -.0432732    -.895116 |
     |----------------------------------------------|
 11. |  3    31   -1.607959   -.0001177   -1.607841 |
 12. |  3    32    .1928903   -.0001177     .193008 |
 13. |  3    33    .6054147   -.0001177    .6055323 |
 14. |  3    34   -.3051899   -.0001177   -.3050722 |
 15. |  3    35    1.114255   -.0001177    1.114373 |
     |----------------------------------------------|
 16. |  4    31   -.0898557    .0011354   -.0909911 |
 17. |  4    32    .6663027    .0011354    .6651673 |
 18. |  4    33   -.3823017    .0011354   -.3834371 |
 19. |  4    34    .4554643    .0011354    .4543289 |
 20. |  4    35   -.6439326    .0011354    -.645068 |
     |----------------------------------------------|
 21. |  5    31    .2606112   -.0572376    .3178489 |
 22. |  5    32   -1.452613   -.0572376   -1.395375 |
 23. |  5    33   -.7583048   -.0572376   -.7010671 |
 24. |  5    34    1.970305   -.0572376    2.027542 |
 25. |  5    35   -.3061868   -.0572376   -.2489491 |
     |----------------------------------------------|
 26. |  6    31    .1273191   -.0758624    .2031815 |
 27. |  6    32    .1132783   -.0758624    .1891407 |
 28. |  6    33   -1.265171   -.0758624   -1.189308 |
 29. |  6    34   -.3444634   -.0758624    -.268601 |
 30. |  6    35    .9897245   -.0758624    1.065587 |
     |----------------------------------------------|
 31. |  7    31    1.365968    .1749991    1.190969 |
 32. |  7    32    .4271485    .1749991    .2521494 |
 33. |  7    33   -.3066736    .1749991   -.4816727 |
 34. |  7    34    .7777075    .1749991    .6027084 |
 35. |  7    35   -1.389155    .1749991   -1.564154 |
     |----------------------------------------------|
 36. |  8    31   -.2772346   -.0689805   -.2082541 |
 37. |  8    32   -.1689324   -.0689805   -.0999519 |
 38. |  8    33    .1919505   -.0689805     .260931 |
 39. |  8    34   -.1805429   -.0689805   -.1115623 |
 40. |  8    35    .0898568   -.0689805    .1588373 |
     |----------------------------------------------|
 41. |  9    31    .1654728    .7130084   -.5475356 |
 42. |  9    32    .6335773    .7130084   -.0794311 |
 43. |  9    33   -.2884277    .7130084   -1.001436 |
 44. |  9    34    1.663885    .7130084    .9508767 |
 45. |  9    35    1.390535    .7130084    .6775261 |
     |----------------------------------------------|
 46. | 10    31   -1.845122   -.1900785   -1.655043 |
 47. | 10    32   -.5377126   -.1900785   -.3476341 |
 48. | 10    33    2.255249   -.1900785    2.445327 |
 49. | 10    34    .6103685   -.1900785     .800447 |
 50. | 10    35   -1.433175   -.1900785   -1.243096 |
     +----------------------------------------------+

. 
. /*
> In fact, the comparison to the average wage wasn't that interes
> ting after all
> (the average is close to 0 by construction), so let's just drop
>  those variables.
> */
. drop average_wage wage_deviation

. 
. /*
> Of course, none of this is any good if we can't show others our
>  results. Stata's
> graphing utilities are extremely large and complicated, but the
>  below
> demonstrates how to make a basic line graph with titles. (Remem
> ber, y-axis
> first, x-axis second)
> */
. line worker_wage_deviation age if id==1, title("Deviations for 
> Worker 1") xtitle("Age") ytitle("Deviation from Mean")

. 
. /*
> 'drop' can actually be used in two ways. The first one is the w
> ay I used it above
> to drop VARIABLES you no longer need. If instead you combine it
>  with a 
> conditional statement, you will drop all OBSERVATIONS meeting t
> hose criteria.
> Let's say we get a call from the people who gathered the data, 
> and they tell us
> the data from worker 8 is total junk. Let's get rid of it.
> */
. drop if id==8
(5 observations deleted)

. tab id

         id |      Freq.     Percent        Cum.
------------+-----------------------------------
          1 |          5       11.11       11.11
          2 |          5       11.11       22.22
          3 |          5       11.11       33.33
          4 |          5       11.11       44.44
          5 |          5       11.11       55.56
          6 |          5       11.11       66.67
          7 |          5       11.11       77.78
          9 |          5       11.11       88.89
         10 |          5       11.11      100.00
------------+-----------------------------------
      Total |         45      100.00

. 
. /*
> The inverse of 'drop' is 'keep'. Let's say we discover only the
>  data from 
> age==32 is valid. We can keep just those data.
> */
. keep if age==32
(36 observations deleted)

. list

     +----------------------------------------------+
     | id   age        wage   worker_~e   worker_~n |
     |----------------------------------------------|
  1. |  1    32   -.3612679    .5142158   -.8754837 |
  2. |  2    32   -1.068483   -.0432732   -1.025209 |
  3. |  3    32    .1928903   -.0001177     .193008 |
  4. |  4    32    .6663027    .0011354    .6651673 |
  5. |  5    32   -1.452613   -.0572376   -1.395375 |
     |----------------------------------------------|
  6. |  6    32    .1132783   -.0758624    .1891407 |
  7. |  7    32    .4271485    .1749991    .2521494 |
  8. |  9    32    .6335773    .7130084   -.0794311 |
  9. | 10    32   -.5377126   -.1900785   -.3476341 |
     +----------------------------------------------+

. 
. /*
> Another important thing to note lest you get confused. '=' is d
> ifferent from 
> '=='. The first one is assignment. It assigns the value on the 
> right hand
> side to the variable on the left hand side. The second is a tes
> t for equality.
> It returns 1 if the values on both sides are identical and 0 ot
> herwise. Other 
> conditional statements (>, <, <=, >=) work the same way. Let's 
> say we want to
> mark all the observations that are more than 1/2 above the work
> er mean. 
> */
. gen big_deviation = (worker_wage_deviation>0.5)

. list

     +---------------------------------------------------------+
     | id   age        wage   worker_~e   worker_~n   big_de~n |
     |---------------------------------------------------------|
  1. |  1    32   -.3612679    .5142158   -.8754837          0 |
  2. |  2    32   -1.068483   -.0432732   -1.025209          0 |
  3. |  3    32    .1928903   -.0001177     .193008          0 |
  4. |  4    32    .6663027    .0011354    .6651673          1 |
  5. |  5    32   -1.452613   -.0572376   -1.395375          0 |
     |---------------------------------------------------------|
  6. |  6    32    .1132783   -.0758624    .1891407          0 |
  7. |  7    32    .4271485    .1749991    .2521494          0 |
  8. |  9    32    .6335773    .7130084   -.0794311          0 |
  9. | 10    32   -.5377126   -.1900785   -.3476341          0 |
     +---------------------------------------------------------+

. 
. /*
> Lastly, we're done with our data for now, so let's save it (eve
> n though
> we've kind of shredded it to pieces) and clear the workspace.
> */
. save "~/Desktop/Econometrics/stata/intro_data", replace
file ~/Desktop/Econometrics/stata/intro_data.dta saved

. clear

. log close
      name:  <unnamed>
       log:  /Users/Sun/Desktop/Econometrics/stata/intro.log
  log type:  text
 closed on:   1 Apr 2017, 08:32:01
-----------------------------------------------------------------
